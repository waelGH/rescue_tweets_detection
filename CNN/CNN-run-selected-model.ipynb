{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Experiments (10-fold cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script for CNN experiments on rescue detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "### imports (1) ##\n",
    "import pandas as pd\n",
    "import numpy as pn\n",
    "from numpy import mean\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import string\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "### imports (2) ##\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "\n",
    "from pickle import load\n",
    "from numpy import array\n",
    "\n",
    "### imports (3) ##\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "### imports (4) ##\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#### functions to convert labels to numerical ####\n",
    "##################################################\n",
    "def class2Index(classList,class2index):\n",
    "    return [class2index[c] for c in classList]\n",
    "\n",
    "\n",
    "def train_classes(classes):\n",
    "    class2index = {}\n",
    "    index2class = {}\n",
    "    classCount = 0\n",
    "    for cl in np.unique(classes):\n",
    "        if cl not in class2index:\n",
    "            class2index[cl] = classCount\n",
    "            index2class[classCount] = cl\n",
    "            classCount += 1\n",
    "            \n",
    "    return class2index,index2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#### functions to clean the corpus ###############\n",
    "##################################################\n",
    "def remove_punc(text): \n",
    "    text = \"\".join([char for char in text if char not in string.punctuation ])\n",
    "    #text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+',text)\n",
    "    return text\n",
    "\n",
    "def remove_url(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return(text)\n",
    "\n",
    "def lower_case(text):\n",
    "    text = text.lower()\n",
    "    return(text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in STOPWORDS]\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_text(text): \n",
    "    # lower case\n",
    "    text_lower = lower_case(text)\n",
    "    \n",
    "    # remove puntuation\n",
    "    text_punc = remove_punc(text_lower) \n",
    "    \n",
    "    #remove URLS\n",
    "    text_url = remove_url(text_punc)\n",
    "    \n",
    "    # tokenization\n",
    "    text_tokens = tokenization(text_url)\n",
    "    \n",
    "    # remove stop words\n",
    "    no_stop_tokens = remove_stopwords(text_tokens)\n",
    "    \n",
    "    return no_stop_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "#########  function to clean and tokenize a corpus (to create a vocab given a corpus)  #################\n",
    "###        input: corpus         output: clean tokens ##################################################\n",
    "########################################################################################################\n",
    "def clean_corpus(corpus):\n",
    "    # convert all to lower case \n",
    "    corpus_lower = lower_case(corpus)\n",
    "    \n",
    "    # remove punctuation\n",
    "    corpus_punc = remove_punc(corpus_lower) \n",
    "    # remove punctuation from each token\n",
    "    #table = str.maketrans('', '', string.punctuation)\n",
    "    #tokens = [w.translate(table) for w in tokens]\n",
    "    \n",
    "    #remove URLS\n",
    "    corpus_url = remove_url(corpus_punc)\n",
    "    \n",
    "    # tokenization\n",
    "    corpus_tokens = tokenization(corpus_url)\n",
    "    # split into tokens by white space\n",
    "    #tokens = corpus.split()\n",
    "    \n",
    "    # remove stop words\n",
    "    no_stop_tokens = remove_stopwords(corpus_tokens)\n",
    "    # filter out stop words\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # tokens = [w for w in tokens if not w in stop_words]\n",
    "    \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    #tokens = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # filter out short tokens\n",
    "    final_tokens = [word for word in no_stop_tokens if len(word) > 1]\n",
    "\n",
    "    return final_tokens\n",
    "\n",
    "########################################################################################################\n",
    "#########  function to clean and tokenize a document based on a given vocabulary   #####################\n",
    "###        input: document         output: clean document's tokens #####################################\n",
    "########################################################################################################\n",
    "def clean_document_vocab(doc, vocab):\n",
    "    # convert to lower case \n",
    "    doc_lower = lower_case(doc)\n",
    "    \n",
    "    # remove punctuation\n",
    "    doc_punc = remove_punc(doc_lower) \n",
    "\n",
    "    #remove URLS\n",
    "    doc_url = remove_url(doc_punc)\n",
    "    \n",
    "    # tokenization\n",
    "    doc_tokens = tokenization(doc_url)\n",
    "    \n",
    "    # remove stop words\n",
    "    doc_no_stop_tokens = remove_stopwords(doc_tokens)\n",
    "    \n",
    "    # filter out tokens not in vocab\n",
    "    tokens = [w for w in doc_no_stop_tokens if w in vocab]\n",
    "    \n",
    "    #tokens = ' '.join(tokens)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Ian/Ida data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#### read mixed data - verified ####################\n",
    "####################################################\n",
    "import pandas as pd\n",
    "\n",
    "path_to_mixed_verif = '/home/wkhal001/Desktop/Mixed_data_verified/Mixed_data__ian_ida_verified.csv'\n",
    "\n",
    "mixed_ida_ian_verified=pd.read_csv(path_to_mixed_verif) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'event', 'text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_ida_ian_verified.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4935\n",
       "1     225\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_ida_ian_verified['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_mixed = mixed_ida_ian_verified[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkhal001/envs/Twitter_crisis/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Data_mixed['cleaned_tweet'] = Data_mixed['text'].apply(lambda x: \" \".join(clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract useful columns \n",
    "df_training = Data_mixed[['text','cleaned_tweet','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.columns= ['non_cleaned_text','text','label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vocabulary and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary created... 11721  tokens\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# Create a vocabulary   (specify the corpus data frame (e.g., labeledDF) #########\n",
    "##################################################################################\n",
    "corpus = ''\n",
    "for i in range(len(df_training)) :\n",
    "    st = df_training.iloc[i][\"non_cleaned_text\"]\n",
    "    corpus = corpus + \" \" + st\n",
    "    \n",
    "#corpus\n",
    "T = clean_corpus(corpus)\n",
    "\n",
    "### count vocabulary with collection counter ####\n",
    "vocab = Counter()\n",
    "vocab.update(T)\n",
    "\n",
    "print('Vocabulary created...',len(vocab),' tokens')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload Pretrained word embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193515 word vectors.\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "########      Load pretrained embedding    #######################################\n",
    "##################################################################################\n",
    "path_to_glove = '/home/wkhal001/Desktop/gensim-data/glove-twitter-200/glove-twitter-200.txt' \n",
    "    \n",
    "# Load the file content in a dictionary\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))\n",
    "#embeddings_index['hurricane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size ... 11748\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "###### create Keras tokenizer and fit text ############\n",
    "#######################################################\n",
    "tokenizer = Tokenizer(num_words=None,oov_token='OOV')\n",
    "tokenizer.fit_on_texts(df_training['text'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Tokenizer vocabulary size ...',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocaublary size: 11748\n",
      "Embedding dimension: 200\n",
      "Create embedding matrix in progress....\n",
      "Embedding matrix created\n",
      "Embedding matrix size 11748\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "########      Initialize the embedding layer    ##################################\n",
    "##################################################################################\n",
    "EMBEDDING_DIM=200\n",
    "vocabulary_size=len(tokenizer.word_index)+1\n",
    "print('Vocaublary size:',vocabulary_size)\n",
    "print('Embedding dimension:',EMBEDDING_DIM)\n",
    "print('Create embedding matrix in progress....')\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print('Embedding matrix created')\n",
    "print('Embedding matrix size',len(embedding_matrix))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# Define encoder architecture Kim model  #################################\n",
    "##########################################################################\n",
    "def create_kim_encoder(length, vocab_size=100, embedding=False, embed_params={}):\n",
    "    ## inputs #####\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    \n",
    "    ## Create the embedding layer  ######################################\n",
    "    if embedding == True:   \n",
    "        embedding_layer = Embedding(embed_params['Tokenizer_size'] + 1,\n",
    "                            embed_params['EMBEDDING_DIM'],\n",
    "                            weights=[embed_params['weights']],\n",
    "                            input_length=embed_params['input_length'],\n",
    "                            trainable=False)\n",
    "        embedding1 = embedding_layer(inputs1)\n",
    "    else: \n",
    "        embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
    "    \n",
    "\n",
    "    # channel 1\n",
    "    #embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
    "    embedding1 = embedding_layer(inputs1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=3, activation='relu')(embedding1)\n",
    "    #drop1 = Dropout(0.3)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=8)(conv1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "\n",
    "    # channel 2\n",
    "    #inputs2 = Input(shape=(length,))\n",
    "    #embedding2 = Embedding(vocab_size, 100)(inputs1)\n",
    "    embedding2 = embedding_layer(inputs1)\n",
    "    conv2 = Conv1D(filters=1024, kernel_size=4, activation='relu')(embedding2)\n",
    "    #drop2 = Dropout(0.3)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=8)(conv2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "\n",
    "    # channel 3\n",
    "    #inputs3 = Input(shape=(length,))\n",
    "    #embedding3 = Embedding(vocab_size, 100)(inputs1)\n",
    "    embedding3 = embedding_layer(inputs1)\n",
    "    conv3 = Conv1D(filters=128, kernel_size=16, activation='relu')(embedding3)\n",
    "    #drop3 = Dropout(0.3)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=6)(conv3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # merge\n",
    "    union = concatenate([flat1, flat2, flat3])\n",
    "    #union = union.reshape(union.size(0), -1)\n",
    "    \n",
    "    # interpretation\n",
    "    #dense1 = Dense(300, activation='relu')(merged)\n",
    "    #outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = keras.Model(inputs=inputs1, outputs=union) #[inputs1, inputs2, inputs3]\n",
    "\n",
    "    # summarize\n",
    "    #print(model.summary())\n",
    "    #plot_model(model, show_shapes=True, to_file='MMD_kim_encoder_kernel_3_4_8.png')\n",
    "  \n",
    "    return model\n",
    "\n",
    "##########################################################################\n",
    "# Define encoder architecture single channel  ############################\n",
    "##########################################################################\n",
    "def create_single_channel_cnn_encoder(length, vocab_size=100):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "\n",
    "    # channel 1\n",
    "    #embedding1 = embedding_layer(vocab_size, 100)(inputs1)\n",
    "    embedding1 = embedding_layer(inputs1)\n",
    "    conv1 = Conv1D(filters=128, kernel_size=8, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    \n",
    "    flat1 = Flatten()(pool1)\n",
    "    model = keras.Model(inputs=inputs1, outputs=flat1) #[inputs1, inputs2, inputs3] outputs=union\n",
    "\n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "    plot_model(model, show_shapes=True, to_file='MMD_single_channel_encoder_kernel_8.png')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "###  Create a classifier on top of the CNN architectures #################\n",
    "##########################################################################\n",
    "def create_classifier(encoder, trainable=True):\n",
    "    num_classes=2\n",
    "    input_shape = (128,)\n",
    "    hidden_units = 512\n",
    "    \n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "        \n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(0.3)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    #features = layers.Dropout(dropout_rate)(features)\n",
    "    #features = layers.Dense(50, activation=\"relu\")(features)\n",
    "    #features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "    \n",
    "    # inputs = keras.Input(shape=input_shape)\n",
    "    # features = encoder(inputs)\n",
    "    # features = layers.Dropout(dropout_rate)(features)\n",
    "    # features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    # features = layers.Dropout(dropout_rate)(features)\n",
    "    # outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cnn-glove-classifier-harvey\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from transformers import AdamW\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from Baseline_Models import Display_metrics,Display_classification_report,Confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=2018, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=2018)\n",
    "\n",
    "X = df_training['text']\n",
    "TX = np.array(X.tolist())\n",
    "\n",
    "Y = df_training['label']\n",
    "TY= np.array(Y.tolist())\n",
    "\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Fold  1 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 182\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 23\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 77\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 44\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 33\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 18144)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.9171309636807533\n",
      "f1-score...... 0.782608695652174\n",
      "recall...... 0.782608695652174\n",
      "recall...... 0.782608695652174\n",
      "------------------------------------------------------\n",
      "--------- Fold  2 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 182\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 23\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 77\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 44\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 36\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 18144)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.897044737965454\n",
      "f1-score...... 0.7906976744186046\n",
      "recall...... 0.7391304347826086\n",
      "recall...... 0.85\n",
      "------------------------------------------------------\n",
      "--------- Fold  3 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 182\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 23\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 77\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 34\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 44\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " model_2 (Functional)        (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 18144)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.9839147745764002\n",
      "f1-score...... 0.9130434782608695\n",
      "recall...... 0.9130434782608695\n",
      "recall...... 0.9130434782608695\n",
      "------------------------------------------------------\n",
      "--------- Fold  4 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 182\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 23\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 77\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 44\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 34\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " model_3 (Functional)        (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 18144)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.8969998621772035\n",
      "f1-score...... 0.878048780487805\n",
      "recall...... 0.782608695652174\n",
      "recall...... 1.0\n",
      "------------------------------------------------------\n",
      "--------- Fold  5 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 182\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 23\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 77\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 36\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 35\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " model_4 (Functional)        (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 18144)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.8763701700958505\n",
      "f1-score...... 0.8695652173913043\n",
      "recall...... 0.8695652173913043\n",
      "recall...... 0.8695652173913043\n",
      "------------------------------------------------------\n",
      "--------- Fold  6 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 183\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 22\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 77\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 44\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 36\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " model_5 (Functional)        (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 18144)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.9591729147141518\n",
      "f1-score...... 0.9268292682926829\n",
      "recall...... 0.8636363636363636\n",
      "recall...... 1.0\n",
      "------------------------------------------------------\n",
      "--------- Fold  7 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 183\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 22\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 44\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 65\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 77\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " model_6 (Functional)        (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 18144)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.917918809049721\n",
      "f1-score...... 0.8636363636363636\n",
      "recall...... 0.8636363636363636\n",
      "recall...... 0.8636363636363636\n",
      "------------------------------------------------------\n",
      "--------- Fold  8 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 183\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 22\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 77\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 36\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 65\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " model_7 (Functional)        (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 18144)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.9337957025271542\n",
      "f1-score...... 0.7999999999999999\n",
      "recall...... 0.7272727272727273\n",
      "recall...... 0.8888888888888888\n",
      "------------------------------------------------------\n",
      "--------- Fold  9 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 183\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 22\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 77\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 36\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 43\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " model_8 (Functional)        (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 18144)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.9678610253209795\n",
      "f1-score...... 0.85\n",
      "recall...... 0.7727272727272727\n",
      "recall...... 0.9444444444444444\n",
      "------------------------------------------------------\n",
      "--------- Fold  10 -------------------------\n",
      "Length train index.... 4644\n",
      "Length test index.... 516\n",
      "postive samples in train...... 183\n",
      "postive samples in validation...... 20\n",
      "postive samples in test...... 22\n",
      "------------------------------------------\n",
      "cleaned train docs (in tokens) loaded....\n",
      "train max.... 77\n",
      "cleaned validation docs (in tokens) loaded....\n",
      "train max.... 33\n",
      "cleaned test docs (in tokens) loaded....\n",
      "test max.... 34\n",
      "Model: \"cnn-glove-classifier-harvey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " model_9 (Functional)        (None, 18144)             3598784   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 18144)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               9290240   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,890,050\n",
      "Trainable params: 12,890,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "calculate preds....\n",
      "AP score for class 1 ---> 0.9412632821723729\n",
      "f1-score...... 0.8108108108108109\n",
      "recall...... 0.6818181818181818\n",
      "recall...... 1.0\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "rep_fold = 1\n",
    "padd_len = 128\n",
    "ls_save_results = []\n",
    "\n",
    "pos_proba_ls = []\n",
    "y_tests_ls = []\n",
    "preds_ls = []\n",
    "\n",
    "################################################\n",
    "######### Classifier parameters ################\n",
    "################################################\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "hidden_units = 256\n",
    "num_epochs = 50\n",
    "dropout_rate = 0.3\n",
    "num_classes = 2\n",
    "################################################\n",
    "################################################\n",
    "################################################\n",
    "\n",
    "for train_index, test_index in skf.split(TX,TY):\n",
    "    print('--------- Fold ',str(rep_fold),'-------------------------')\n",
    "    print('Length train index....',len(train_index))\n",
    "    print('Length test index....',len(test_index))\n",
    "    \n",
    "    #### training/testing data ########################################\n",
    "    X_train, X_test = TX[train_index], TX[test_index]\n",
    "    y_train, y_test = TY[train_index], TY[test_index]\n",
    "    \n",
    "    Train_X_cv, val_X, Train_Y_cv, val_Y = train_test_split(X_train,y_train, \n",
    "                                                            random_state=2018, \n",
    "                                                            test_size=0.1,\n",
    "                                                            stratify=y_train)\n",
    "        \n",
    "    ####### check distribution of positive samples on each fold ######\n",
    "    count_test = (y_test == 1).sum()\n",
    "    count_train = (Train_Y_cv == 1).sum()\n",
    "    count_val = (val_Y == 1).sum()\n",
    "    print('postive samples in train......',count_train)\n",
    "    print('postive samples in validation......',count_val)\n",
    "    print('postive samples in test......',count_test)\n",
    "    print('------------------------------------------')\n",
    "    ###################################################################\n",
    "    \n",
    "    train_documents = list()\n",
    "    for row in Train_X_cv: \n",
    "        tweet =  row   #row[\"text\"]\n",
    "        tokens = clean_document_vocab(tweet, vocab)\n",
    "        train_documents.append(tokens)\n",
    "    print('cleaned train docs (in tokens) loaded....')\n",
    "    max_length1 = max([len(s) for s in train_documents])\n",
    "    print('train max....',max_length1)\n",
    "    \n",
    "    validation_documents = list()\n",
    "    for row in val_X: \n",
    "        tweet =  row   #row[\"text\"]\n",
    "        tokens = clean_document_vocab(tweet, vocab)\n",
    "        validation_documents.append(tokens)\n",
    "    print('cleaned validation docs (in tokens) loaded....')\n",
    "    max_length1 = max([len(s) for s in validation_documents])\n",
    "    print('train max....',max_length1)\n",
    "    \n",
    "    test_documents = list()\n",
    "    for row in X_test: \n",
    "        tweet =  row   #row[\"text\"]\n",
    "        tokens = clean_document_vocab(tweet, vocab)\n",
    "        test_documents.append(tokens)\n",
    "    print('cleaned test docs (in tokens) loaded....')\n",
    "    max_length1 = max([len(s) for s in test_documents])\n",
    "    print('test max....',max_length1)\n",
    "    \n",
    "    # covert input text to sequence of indices\n",
    "    train_encoded_docs = tokenizer.texts_to_sequences(train_documents)\n",
    "    val_encoded_docs = tokenizer.texts_to_sequences(validation_documents)\n",
    "    test_encoded_docs = tokenizer.texts_to_sequences(test_documents)\n",
    "\n",
    "    Xtrain = pad_sequences(train_encoded_docs, maxlen=padd_len, padding='post')\n",
    "    Xval = pad_sequences(val_encoded_docs, maxlen=padd_len, padding='post')\n",
    "    Xtest = pad_sequences(test_encoded_docs, maxlen=padd_len, padding='post')\n",
    "\n",
    "    train_labels = Train_Y_cv.tolist()\n",
    "    dev_labels = val_Y.tolist()\n",
    "    test_labels = y_test.tolist()\n",
    "\n",
    "    ###################################################################\n",
    "    ############## Create CNN model in Keras ##########################\n",
    "    ###################################################################\n",
    "    embed_params={'EMBEDDING_DIM':EMBEDDING_DIM,'Tokenizer_size':len(tokenizer.word_index),'weights':embedding_matrix,'input_length':128}\n",
    "    encoder = create_kim_encoder(128, vocab_size,True,embed_params)\n",
    "    classifier = create_classifier(encoder)\n",
    "    classifier.summary()\n",
    "    \n",
    "    ###################################################################\n",
    "    ############## Train CNN model  ###################################\n",
    "    ###################################################################\n",
    "    training_padded = np.array(Xtrain)\n",
    "    training_labels = np.array(train_labels)\n",
    "\n",
    "    validation_padded = np.array(Xval)\n",
    "    validation_labels = np.array(dev_labels)\n",
    "    \n",
    "    testing_padded = np.array(Xtest)\n",
    "    testing_labels = np.array(test_labels)\n",
    "\n",
    "    # compile classifier\n",
    "    classifier.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    ###### Save model ####################################\n",
    "    model_name = 'f_cnn_ian_ida_fold'+ str(rep_fold) + '.h5'\n",
    "\n",
    "    # Load the model\n",
    "    classifier = load_model(model_name)\n",
    "    #classifier.save(model_name)\n",
    "    ######################################################\n",
    "    \n",
    "    ###################################################################\n",
    "    ############## Predict using CNN model  ###########################\n",
    "    ###################################################################\n",
    "    print('calculate preds....')\n",
    "    predictions = classifier.predict(testing_padded)\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    dict_r = classification_report(y_test.tolist(), preds, output_dict = True)\n",
    "\n",
    "    ### calculate probs for precision-recall curve calculation ######\n",
    "    pos_probs = predictions[:, 1]\n",
    "    pos_proba_ls.append(pos_probs)\n",
    "    y_tests_ls.append(y_test.tolist())\n",
    "    preds_ls.append(preds)\n",
    "    #################################################################\n",
    "    \n",
    "    ###### calculate precision-recall curve and metric #########\n",
    "    _fold_AP = average_precision_score(y_test.tolist(),pos_probs)\n",
    "    print(\"AP score for class 1 --->\",_fold_AP)\n",
    "    ############################################################\n",
    "    \n",
    "    \n",
    "    ### calculate results ####################################\n",
    "    _f1 = dict_r['1']['f1-score']\n",
    "    _recall = dict_r['1']['recall']\n",
    "    _precision = dict_r['1']['precision']\n",
    "    ##########################################################\n",
    "\n",
    "    print('f1-score......',_f1)\n",
    "    print('recall......',_recall)\n",
    "    print('recall......',_precision)\n",
    "    \n",
    "    fold_results = {'report':dict_r,'f1':_f1,'recall':_recall,'precision':_precision,'AP':_fold_AP,'AP_list':pos_probs,'ytest':y_test.tolist()}\n",
    "    ls_save_results.append(fold_results)\n",
    "\n",
    "\n",
    "    rep_fold = rep_fold + 1\n",
    "    print('------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores =[]\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "AP_scores =[]\n",
    "\n",
    "for i in ls_save_results:\n",
    "    AP_scores.append(i['AP'])\n",
    "    f1_scores.append(i['report']['1']['f1-score'])\n",
    "    recall_scores.append(i['report']['1']['recall'])\n",
    "    precision_scores.append(i['report']['1']['precision'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------  CNN - 10-cv results (IAN/IDA)----------------\n",
      "average AP 0.9291472242280041\n",
      "stdev AP 0.03446108924069376\n",
      "\n",
      "\n",
      "average F1 0.8485240288950615\n",
      "stdev F1 0.05088664986746529\n",
      "\n",
      "\n",
      "average recall 0.799604743083004\n",
      "stdev recall 0.07455481028152039\n",
      "\n",
      "\n",
      "average precision 0.9112187088274044\n",
      "stdev precision 0.07419165261388087\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print('----------------  CNN - 10-cv results (IAN/IDA)----------------')\n",
    "print('average AP',statistics.mean(AP_scores))\n",
    "print('stdev AP',statistics.stdev(AP_scores))\n",
    "print('\\n')\n",
    "print('average F1',statistics.mean(f1_scores))\n",
    "print('stdev F1',statistics.stdev(f1_scores))\n",
    "print('\\n')\n",
    "print('average recall',statistics.mean(recall_scores))\n",
    "print('stdev recall',statistics.stdev(recall_scores))\n",
    "print('\\n')\n",
    "print('average precision',statistics.mean(precision_scores))\n",
    "print('stdev precision',statistics.stdev(precision_scores))\n",
    "print('\\n')\n",
    "print('-----------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_proba_arr = np.concatenate(pos_proba_ls)\n",
    "pos_y_test_arr = np.concatenate(y_tests_ls)\n",
    "pos_preds_arr = np.concatenate(preds_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"cnn_probs_ian_ida_best_model.txt\",pos_proba_arr)\n",
    "np.savetxt(\"cnn_y_test_ian_ida_best_model.txt\",pos_y_test_arr)\n",
    "np.savetxt(\"cnn_preds_ian_ida_best_model.txt\",pos_preds_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved data in text files ##\n",
    "# Function to load a list from a text file\n",
    "def load_list_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read lines and strip newline characters\n",
    "        items = [float(line.strip()) for line in file]\n",
    "    return items\n",
    "\n",
    "# Specify the path to your text file\n",
    "file_path_probs = 'cnn_probs_ian_ida_best_model.txt'\n",
    "file_path_preds = 'cnn_preds_ian_ida_best_model.txt'\n",
    "file_path_y = 'cnn_y_test_ian_ida_best_model.txt'\n",
    "\n",
    "# Load the list\n",
    "probs_cnn = load_list_from_file(file_path_probs)\n",
    "preds_cnn = load_list_from_file(file_path_preds)\n",
    "ytest_cnn = load_list_from_file(file_path_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f4102b18b50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "cm = confusion_matrix(ytest_cnn, preds_cnn, labels=np.unique(ytest_cnn))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(ytest_cnn))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.figure_.savefig('confusion_matrix_cnn_ian_ida_final.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('cnn_probs_ian_ida_best_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(pos_proba_arr, f)\n",
    "    \n",
    "# with open('cnn_y_test_ian_ida_best_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(pos_y_test_arr, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "#pos_proba_ls \n",
    "#y_tests_ls \n",
    "pos_proba_arr = np.concatenate(pos_proba_ls)\n",
    "y_tests_arr = np.concatenate(y_tests_ls)\n",
    "\n",
    "###### calculate precision-recall curve and metric #########\n",
    "precision, recall, thresholds = precision_recall_curve(y_tests_arr,pos_proba_arr)\n",
    "\n",
    "display = PrecisionRecallDisplay.from_predictions(y_tests_arr, pos_proba_arr, name=\"CNN\")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
